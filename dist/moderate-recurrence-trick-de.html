<html>
<head>
    <title>Eine Technik zur Vereinfachung von aus Rekursionsgleichungen entstandenen Wachstumsklassen</title>
    <link rel="stylesheet" type="text/css" href="/css/style.css" />
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      processEscapes: true,
      menuSettings: { inTabOrder: false },
      "AssistiveMML": {
         disabled: false,
         styles: {
            ".MJX_Assistive_MathML": {
                position:"absolute!important",
                clip: (MathJax.Hub.Browser.isMSIE && (document.documentMode||0) < 8 ?
                    "rect(1px 1px 1px 1px)" : "rect(1px, 1px, 1px, 1px)"),
                padding: "1px 0 0 0!important",
                border: "0!important",
                height: "1px!important",
                width: "1px!important",
                overflow: "hidden!important",
                display:"block!important"
            }
        }
      }
    });
    </script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, type=text/html" charset="UTF-8">
    <link rel="stylesheet" href="/css/style.css">
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    <!-- Cloudflare Web Analytics -->
    <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "5b8562dcfaa5413ba2aea8294b9d585e"}'></script><!-- End Cloudflare Web Analytics -->
</head>
<body>
    <h2>Eine Technik zur Vereinfachung von aus Rekursionsgleichungen entstandenen Wachstumsklassen</h2>

<blockquote>
<p>Kannst du die asymptotische Wachstumsklassen der Folgen ausrechnen, die durch die folgenden Rekursionsgleichungen definiert sind? <script type="math/tex; mode=display">\begin{align*}T(n) &= T(n - \sqrt{n}) + \tfrac{1}{\sqrt{n}} \\ T(n) &= T(n - \sqrt{n}) + \sqrt{\tfrac{\log n}{n}} \\ T(n) &= T(n-\log^2 n) + \tfrac{1}{n} \\ T(n) &= T(n ~ / ~ 2) + \tfrac{1}{\log n} \\ T(n) &= T(n ~ / ~ 2) + e^{\sqrt{\log n}} \\ T(n) &= 2 ~ T(n ~ / ~ 2) + \tfrac{n\log\log n}{\log n}\end{align*}</script>
</p>
</blockquote>

<p>In einem späteren Entwurf meiner Bachelorthese, die hauptsächlich die grundsätzliche Eigenschaften der asymptotischen Wachstumsklassen und die Partialsummen behandelte, habe ich mich ein bisschen in die Rekursionsgleichungen vertieft. Leider war dieser Abschnitt der These nicht ausführlich genug entwickelt, um im entgültigen Entwurf gehalten zu sein. Aber drin gab es eine tolle Lösungstechnik, die mindestens einen Blogeintrag verdient!</p>

<p>Ein Schlüsselbegriff, der innerhalb meiner These entwickelt wird, ist die <em>Mäßigkeit</em> der Wachstumsklassen. Meiner Definition nach, die Wachstumsklasse von einer Folge $(a_n)$ ist <strong>mäßig</strong>, wenn <script type="math/tex; mode=display">(b_n)\in\Theta(n) ~ \implies ~ a_{b_n} = \Theta(a_n)</script> d.h., wenn man $(a_n)$ durch einer Folge $(b_n)$, die der linealen Wachstumsklasse entspricht, neu indiziert, ist seine Wachstumsklasse nicht geändert. Diese Eigenschaft hängt nur von der Wachstumsklasse von $(a_n)$ ab, also, wenn $a_n = \Theta(a'_n)$ und $(a_n')$ mäßig ist, dann muss $(a_n)$ auch mäßig sein. Viele häufige Wachstumsklassen zeigen diese Eigenschaft (z.B. polynomiales Wachstum, logarithmisches Wachstum, alle ihre Summen, Produkte und Wurzeln, usw) und es hat zur Folge viele andere günstige Eigenschaften.</p>

<p>Unter ihnen ist eine einfache aber sehr wichtige Eigenschaft, die sich uns als sehr nützlich zur Lösung der Rekursionsgleichungen beweisen wird. Es heißt: wenn $(a_n)$ mäßig ist und $b_n = \mathcal O(n)$, dann kann mann folgern, dass <script type="math/tex; mode=display">\sum_{k=n}^{n + b_n} a_n = \Theta(a_n b_n)</script> Diese Schlussfolgerung lässt sich ganz einfach beweisen und es ist von selbst nicht so bahnbrechend, aber wir werden gleich sehen, wie es zur Trivialisierung einiger Rekursionsgleichungen führt.</p>

<p>Überleg mal die folgende Rekursionsgleichung: <script type="math/tex; mode=display">T(n) = T(n - a_n) + b_n</script> wo $T(0) &gt; 0$ und $(a_n)$ eine Folge von natürlichen Zahlen ist, derart, dass $a_n &lt; n$ für alle $n\in\mathbb N$ (damit $T(n-a_n)$ wohldefiniert ist). Unter bestimmten Bedingungen kann man beweisen, dass die Wachstumsklasse von $T$ nur von den respektiven Wachstumsklassen von $(a_n)$ und $(b_n)$ abhängig ist. Diese Unabhängigkeit hat zur Folge, dass man $(a_n)$ oder $(b_n)$ willkürlich durch günstiger Folgen ersetzen kann, die aus der gleichen Wachstumsklassen gezogen sind, um die Berechnung der Wachstumsklasse von $T$ zu erleichtern. Und wenn $(a_n)$ und $(b_n)$ <em>mäßig</em> sind, dann (so behauptet die Eigenschaft der mäßigen Wachstumsklassen, auf die wir hingewiesen haben) trifft zu: <script type="math/tex; mode=display">b_n = \Theta\bigg(\sum_{k=n-a_n+1}^n \frac{b_k}{a_k}\bigg)</script> damit die durch der folgenden Rekursionsgleichung definierten Funktion $T^\ast$ der gleichen Wachstumsklasse als $T$ entspricht: <script type="math/tex; mode=display">T^\ast(n) = T^\ast (n - a_n) + \sum_{k=n-a_n + 1}^n \frac{b_k}{a_k}</script> Aber es ist ganz einfach zu beweisen, dass die folgende Definition für $T^\ast$ diese Rekursionsgleichung bestätigt: <script type="math/tex; mode=display">T^\ast(n) = \sum_{k=0}^n \frac{b_k}{a_k}</script> und deshalb: <script type="math/tex; mode=display">T(n) = \Theta\bigg(\sum_{k=0}^n \frac{b_k}{a_k}\bigg)</script> Diese Technik reduziert die Berechnung der Wachstumsklasse von $T$ auf die Berechnung der Wachstumsklasse dieser Partialsumme, und in meiner These habe ich ganz ausführlich viele Technik zur Berechnung der Wachtumsklasse von Partialsummen entwickelt. Kurz gefasst wissen wir, dass solange $(a_n)$ und $(b_n)$ bestimmte ziemlich einfache Bedingungen erfüllen:</p>

<p>
<script type="math/tex; mode=display">T(n) = T(n - a_n) + b_n ~ \implies ~ T(n) = \Theta\bigg(\sum_{k=1}^{a_n} \frac{b_k}{a_k}\bigg)</script>
</p>

<p>Zum Beispiel:</p>

<p>
<script type="math/tex; mode=display">\begin{align*}T(n) = T(n - \sqrt{n}) + \frac{1}{\sqrt{n}} ~ &\implies ~ T(n) = \Theta(\log n) \\ T(n) = T(n - \sqrt{n}) + \sqrt{\frac{\log n}{n}} ~ &\implies ~ T(n) = \Theta\big((\log n)^{3/2}\big) \\ T(n) = T(n-\log n) + \frac{1}{n} ~ &\implies ~ T(n) = \Theta(\log\log n) \\ T(n) = T(n-\log^2 n) + \frac{1}{n} ~ &\implies ~ T(n) = \Theta(1)\end{align*}</script>
</p>

<p>Die gleiche Technik kann einer ähnlichen Klasse von Rekursiongleichungen gewidmet werden: die sogennante <em>Teile-und-Herrsche Rekursionen</em>, die sehr oft in der Lehre von theoretischen Algorithmen auftuachen und die Folgende Form annehmen:</p>

<p>
<script type="math/tex; mode=display">T(n) = \alpha ~ T(n ~ / ~\beta) + a_n</script>
</p>

<p>wo $\alpha &gt; 0$ und $\beta &gt; 1$. Bevor man jene Technik anwendet muss man einen Ersatz durchführen: wenn man $c = \log_\beta\alpha$ definiert, dann kann man folgern</p>

<p>
<script type="math/tex; mode=display">n^{-c} T(n) = (n/\beta)^{-c} ~ T(n ~ / ~\beta) + n^{-c} a_n</script>
</p>

<p>und man kann deshalb beweisen (hier verbergen wir viele mühsame Einzelheiten, die mann in einem gültigen Beweis durcharbeiten muss), dass $T(n) = \Theta(n^c T^\ast(n))$, wo $T^\ast$ durch der folgenden Rekursionsgleichung definiert ist: <script type="math/tex; mode=display">T^\ast(n) = T^\ast(n/\beta) + \frac{a_n}{n^c}</script> Diese Rekursionsgleichung ist geeignet für unsere frühere Technik. Wenn $(a_n)$ mäßig ist, dann würde $T^\ast$ der gleichen Wachstumsklasse entsprechen, wenn wir es so definiert hätten: <script type="math/tex; mode=display">T^\ast(n) = T^\ast(n/\beta) + \sum_{k=n/\beta + 1}^n \frac{a_k}{k^{c+1}}</script> Wie früher, diese Rekursionsgleichung lässt sich ganz einfach durch einer analytischen Formel simplifizieren: <script type="math/tex; mode=display">T^\ast(n) = \sum_{k=1}^n \frac{a_k}{n^{c+1}}</script> damit <script type="math/tex; mode=display">T(n) = \Theta\bigg(n^c \sum_{k=1}^n \frac{a_k}{n^{c+1}}\bigg)</script> Also, insgesamt wissen wir (noch mal durch bestimmten Eigenschaften von $(a_n)$ bedingt), dass</p>

<p>
<script type="math/tex; mode=display">T(n) = \alpha ~ T(n ~ / ~\beta) + a_n ~ \implies ~ T(n) = \Theta\bigg(n^c \sum_{k=1}^n \frac{a_k}{k^{c+1}}\bigg)</script>
</p>

<p>Diese Technik lässt sich auch in vielen Fällen anwenden, in den der sogennanten <a href="https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms)">Master-Theorem</a> wegen Beschränkungen auf $(a_n), \alpha, \beta$ leider nicht gilt, sogar ohne auf fortgeschrittene Befunde z.B. von dem Kalkül zu beruhen. Zum Beispiel, hier sind ein paar von aus Rekursionsgleichungen entstandene asymptotische Formeln, die sich durch den Master-Theorem nicht lösen lassen:</p>

<p>
<script type="math/tex; mode=display">\begin{align*}T(n) = T(n ~ / ~ 2) + \frac{1}{\log n} ~ &\implies ~ T(n) = \Theta(\log \log n) \\ T(n) = T(n ~ / ~ 2) + e^{\sqrt{\log n}} ~ &\implies ~ T(n) = \Theta\big(n\sqrt{\log n}\cdot e^{\sqrt{\log n}}\big) \\ T(n) = 2 ~ T(n ~ / ~ 2) + \frac{n\log\log n}{\log n} ~ &\implies ~ T(n) = \Theta(n \log^2\log n)\end{align*}</script>
</p>

    <br>
<a href="/">go to homepage</a>
<hr>
<div id="license-statement">The posts on this website are licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC-by-NC 4.0</a>.</div>
<div id="notbyai"><a href="https://notbyai.fyi/"><img src="/img/written-by-human.png"/><img src="/img/illustrated-by-human.png"/></a></div>
</body>
</html>